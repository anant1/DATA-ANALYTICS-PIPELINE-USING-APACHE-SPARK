{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SQLContext\n",
    "from pyspark import SparkContext\n",
    "sc =SparkContext()\n",
    "sqlContext = SQLContext(sc)\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+\n",
      "|Category|                Body|\n",
      "+--------+--------------------+\n",
      "|business|SEOUL  WITH A FAL...|\n",
      "|business|JEFFERSON CITY  M...|\n",
      "|business|WASHINGTON  THE T...|\n",
      "|business|REUTERS    METLIF...|\n",
      "|  sports|DALLAS  WHEN DALL...|\n",
      "+--------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "stop_word_list = stopwords.words('english')\n",
    "#  to quickly test if a word is not a stop word, use a set:\n",
    "stop_word_set = set(stop_word_list)\n",
    "stop_word_set = list(stop_word_set)\n",
    "data = sqlContext.read.format('com.databricks.spark.csv').options(header='true', inferschema='true').load('articles-train.csv')\n",
    "drop_list = ['Dates', 'Topic', 'Page']\n",
    "data = data.select([column for column in data.columns if column not in drop_list])\n",
    "data.show(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Category: string (nullable = true)\n",
      " |-- Body: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Top 20 crime categories:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-----+\n",
      "|     Category|count|\n",
      "+-------------+-----+\n",
      "|     business| 2309|\n",
      "|     politics| 1666|\n",
      "|       sports|  571|\n",
      "|entertainment|  464|\n",
      "+-------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "data.groupBy(\"Category\") \\\n",
    "    .count() \\\n",
    "    .orderBy(col(\"count\").desc()) \\\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|                Body|count|\n",
      "+--------------------+-----+\n",
      "|HERE IS THE APRIL...|    9|\n",
      "|BEVERLY HILLS  CA...|    9|\n",
      "|WANT TO GET THIS ...|    8|\n",
      "|BEIJING  U S  TRE...|    8|\n",
      "|JOANNE KIM AND AY...|    7|\n",
      "|WANT TO GET THIS ...|    7|\n",
      "|INDIANAPOLIS  IND...|    7|\n",
      "|WANT TO GET THIS ...|    7|\n",
      "|WASHINGTON  FPI M...|    7|\n",
      "|INDIANAPOLIS  OKL...|    7|\n",
      "|LONDON  A RESURGE...|    7|\n",
      "|AUBURN  WASH   PR...|    6|\n",
      "|IT FEELS LIKE KAN...|    6|\n",
      "|PHOENIX  WHEN FOR...|    6|\n",
      "|INDIANAPOLIS  IND...|    6|\n",
      "|LONDON  BRITAIN S...|    6|\n",
      "|WE MAY NEVER STOP...|    6|\n",
      "|AT THE 2014 CONSU...|    6|\n",
      "|HERE ARE THE WEEK...|    6|\n",
      "|VENTURA  CALIF   ...|    6|\n",
      "+--------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.groupBy(\"Body\") \\\n",
    "    .count() \\\n",
    "    .orderBy(col(\"count\").desc()) \\\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import RegexTokenizer, StopWordsRemover, CountVectorizer\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "# regular expression tokenizer\n",
    "regexTokenizer = RegexTokenizer(inputCol=\"Body\", outputCol=\"words\", pattern=\"\\\\W\")\n",
    "# stop words\n",
    "# add_stopwords = [\"http\",\"https\",\"amp\",\"rt\",\"t\",\"c\",\"the\"] \n",
    "stopwordsRemover = StopWordsRemover(inputCol=\"words\", outputCol=\"filtered\").setStopWords(stop_word_set)\n",
    "# bag of words count\n",
    "# countVectors = CountVectorizer(inputCol=\"filtered\", outputCol=\"features\", vocabSize=10000, minDF=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import OneHotEncoder, StringIndexer, VectorAssembler\n",
    "# label_stringIdx = StringIndexer(inputCol = \"Category\", outputCol = \"label\")\n",
    "# pipeline = Pipeline(stages=[regexTokenizer, stopwordsRemover, countVectors, label_stringIdx])\n",
    "# # Fit the pipeline to training documents.\n",
    "# pipelineFit = pipeline.fit(data)\n",
    "# dataset = pipelineFit.transform(data)\n",
    "# dataset.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set seed for reproducibility\n",
    "# (trainingData, testData) = dataset.randomSplit([0.8, 0.2], seed = 100)\n",
    "# print(\"Training Dataset Count: \" + str(trainingData.count()))\n",
    "# print(\"Test Dataset Count: \" + str(testData.count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------+-------------+------------------------------+-----+----------+\n",
      "|                          Body|     Category|                   probability|label|prediction|\n",
      "+------------------------------+-------------+------------------------------+-----+----------+\n",
      "|DALIAN MANILA  CHINA PLANS ...|     business|[0.9993406144602194,1.38312...|  0.0|       0.0|\n",
      "|LONDON FRANKFURT  GERMANY S...|     business|[0.9980119859619365,4.94516...|  0.0|       0.0|\n",
      "|SYDNEY  AUSTRALIA S BIGGEST...|     business|[0.997918087143643,0.001395...|  0.0|       0.0|\n",
      "|PARIS  SOCGEN S CHIEF EXECU...|     business|[0.997250963812292,0.001054...|  0.0|       0.0|\n",
      "|ADEN  YEMEN  THE YOUNG MOTH...|     business|[0.9964283193746383,8.25149...|  0.0|       0.0|\n",
      "|ADEN  YEMEN  THE YOUNG MOTH...|     business|[0.9964283193746383,8.25149...|  0.0|       0.0|\n",
      "|HONG KONG  A GADGET MAKER  ...|     business|[0.9952530049599432,0.00187...|  0.0|       0.0|\n",
      "|HONG KONG  A GADGET MAKER  ...|     business|[0.9952530049599432,0.00187...|  0.0|       0.0|\n",
      "|HONG KONG  A GADGET MAKER  ...|entertainment|[0.9952530049599432,0.00187...|  3.0|       0.0|\n",
      "|LPC    THE SIZE OF FUND FIN...|     business|[0.9947368764797554,0.00136...|  0.0|       0.0|\n",
      "|LPC    THE SIZE OF FUND FIN...|     business|[0.9947368764797554,0.00136...|  0.0|       0.0|\n",
      "|LOS ANGELES LONDON  SWISS B...|     business|[0.9943281572841745,0.00255...|  0.0|       0.0|\n",
      "|TORONTO  FOR ABOUT AN HOUR ...|     business|[0.9940307922171391,0.00146...|  0.0|       0.0|\n",
      "|BEIJING HONG KONG  CHINESE ...|     business|[0.9933015793572394,0.00104...|  0.0|       0.0|\n",
      "|PARIS  THE FRENCH FINANCE M...|     business|[0.9916311890367605,0.00552...|  0.0|       0.0|\n",
      "|REUTERS    TYSON FOODS INC ...|     business|[0.991278126599585,0.004102...|  0.0|       0.0|\n",
      "|FRANKFURT  THE EUROPEAN CEN...|     business|[0.9905817826204851,0.00543...|  0.0|       0.0|\n",
      "|LONDON  BRITISH MANUFACTURI...|     business|[0.9902443588753802,0.00720...|  0.0|       0.0|\n",
      "|PARIS  PRESSURE ON AIR FRAN...|     business|[0.9902183367998199,0.00498...|  0.0|       0.0|\n",
      "|PARIS  PRESSURE ON AIR FRAN...|     business|[0.9902183367998199,0.00498...|  0.0|       0.0|\n",
      "+------------------------------+-------------+------------------------------+-----+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import HashingTF, IDF\n",
    "label_stringIdx = StringIndexer(inputCol = \"Category\", outputCol = \"label\")\n",
    "hashingTF = HashingTF(inputCol=\"filtered\", outputCol=\"rawFeatures\", numFeatures=10000)\n",
    "idf = IDF(inputCol=\"rawFeatures\", outputCol=\"features\", minDocFreq=5) #minDocFreq: remove sparse terms\n",
    "pipeline = Pipeline(stages=[regexTokenizer, stopwordsRemover, hashingTF, idf, label_stringIdx])\n",
    "pipelineFit = pipeline.fit(data)\n",
    "dataset = pipelineFit.transform(data)\n",
    "(trainingData, testData) = dataset.randomSplit([0.8, 0.2], seed = 324)\n",
    "lr = LogisticRegression(maxIter=20, regParam=0.3, elasticNetParam=0)\n",
    "lrModel = lr.fit(trainingData)\n",
    "predictions = lrModel.transform(testData)\n",
    "predictions.filter(predictions['prediction'] == 0) \\\n",
    "    .select(\"Body\",\"Category\",\"probability\",\"label\",\"prediction\") \\\n",
    "    .orderBy(\"probability\", ascending=False) \\\n",
    "    .show(n = 20, truncate = 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6566287185364578"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "evaluator = MulticlassClassificationEvaluator(predictionCol=\"prediction\")\n",
    "evaluator.evaluate(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+--------------------+\n",
      "|     Category|                Body|\n",
      "+-------------+--------------------+\n",
      "|     business|CAIRO  EGYPT WILL...|\n",
      "|     business|WANT TO GET THIS ...|\n",
      "|     politics|WASHINGTON  U S  ...|\n",
      "|     business|WITH THE ARRIVAL ...|\n",
      "|entertainment|ON THURSDAY  SOON...|\n",
      "+-------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test = sqlContext.read.format('com.databricks.spark.csv').options(header='true', inferschema='true').load('articles-test.csv')\n",
    "drop_list = ['Dates', 'Topic', 'Page']\n",
    "test = data.select([column for column in data.columns if column not in drop_list])\n",
    "test.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-----+\n",
      "|     Category|count|\n",
      "+-------------+-----+\n",
      "|     business|  435|\n",
      "|     politics|  352|\n",
      "|       sports|  123|\n",
      "|entertainment|   90|\n",
      "+-------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "test.groupBy(\"Category\") \\\n",
    "    .count() \\\n",
    "    .orderBy(col(\"count\").desc()) \\\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_stringIdx = StringIndexer(inputCol = \"Category\", outputCol = \"label\")\n",
    "hashingTF = HashingTF(inputCol=\"filtered\", outputCol=\"rawFeatures\", numFeatures=10000)\n",
    "idf = IDF(inputCol=\"rawFeatures\", outputCol=\"features\", minDocFreq=5) #minDocFreq: remove sparse terms\n",
    "pipeline = Pipeline(stages=[regexTokenizer, stopwordsRemover, hashingTF, idf, label_stringIdx])\n",
    "pipelineFit = pipeline.fit(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "testset = pipelineFit.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------+--------+------------------------------+-----+----------+\n",
      "|                          Body|Category|                   probability|label|prediction|\n",
      "+------------------------------+--------+------------------------------+-----+----------+\n",
      "|LONDON  LLOYD S OF LONDON  ...|business|[0.9987644291294391,5.51420...|  0.0|       0.0|\n",
      "|NEW YORK  BILLIONAIRE INVES...|politics|[0.9971454845961765,8.76934...|  1.0|       0.0|\n",
      "|NEW YORK  BILLIONAIRE INVES...|business|[0.9971454845961765,8.76934...|  0.0|       0.0|\n",
      "|ATHENS PATRAS  GREECE  GREE...|business|[0.9956880840988583,0.00165...|  0.0|       0.0|\n",
      "|LPC    THE SIZE OF FUND FIN...|business|[0.9938978451651596,0.00168...|  0.0|       0.0|\n",
      "|SAN FRANCISCO  MOST BIG BAN...|business|[0.9932966005974454,0.00251...|  0.0|       0.0|\n",
      "|LOS ANGELES LONDON  SWISS B...|business|[0.9931797480241308,0.00275...|  0.0|       0.0|\n",
      "|LONDON  A RESURGENT DOLLAR ...|business|[0.991502433831096,0.006527...|  0.0|       0.0|\n",
      "|FRANKFURT  THE INCOMING BOS...|business|[0.9909443833289995,0.00310...|  0.0|       0.0|\n",
      "|TORONTO  FOR ABOUT AN HOUR ...|business|[0.9904548718511379,0.00336...|  0.0|       0.0|\n",
      "|FRANKFURT BERLIN  GERMANY S...|business|[0.9903236776069723,0.00415...|  0.0|       0.0|\n",
      "|HOUSTON  CONOCOPHILLIPS IS ...|business|[0.9877545142156476,0.00714...|  0.0|       0.0|\n",
      "|FRANKFURT  THE EUROPEAN CEN...|business|[0.986613008847953,0.008522...|  0.0|       0.0|\n",
      "|REUTERS    TYSON FOODS INC ...|business|[0.9848354933900315,0.00755...|  0.0|       0.0|\n",
      "|LONDON  BANKS HAVE PUSHED O...|business|[0.9831760212598822,0.01358...|  0.0|       0.0|\n",
      "|LONDON  BANKS HAVE PUSHED O...|business|[0.9831760212598822,0.01358...|  0.0|       0.0|\n",
      "|THIRTY FIVE YEARS AGO  HOLL...|business|[0.9808523959331336,0.00958...|  0.0|       0.0|\n",
      "|SAN FRANCISCO  SINCE APPLE ...|business|[0.9798863299322348,0.00534...|  0.0|       0.0|\n",
      "|DRUGMAKER MERCK S FIRST QUA...|business|[0.9787372096007377,0.00747...|  0.0|       0.0|\n",
      "|DETROIT  MOST MAJOR AUTOMAK...|business|[0.9786669850535079,0.00605...|  0.0|       0.0|\n",
      "+------------------------------+--------+------------------------------+-----+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = lrModel.transform(testset)\n",
    "predictions.filter(predictions['prediction'] == 0) \\\n",
    "    .select(\"Body\",\"Category\",\"probability\",\"label\",\"prediction\") \\\n",
    "    .orderBy(\"probability\", ascending=False) \\\n",
    "    .show(n = 20, truncate = 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6517946810259405"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluator = MulticlassClassificationEvaluator(predictionCol=\"prediction\")\n",
    "evaluator.evaluate(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Naive Bayes\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
